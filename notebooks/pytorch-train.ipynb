{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "557b54fd",
   "metadata": {},
   "source": [
    "# UFC Predictor\n",
    "\n",
    "Train an AI model to predict UFC fights and method of victory.\n",
    "\n",
    "Notebook for:\n",
    "- Feature Selection\n",
    "- Feature encoding/normalization\n",
    "- Model Selection/Training/Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "493a83f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.7.1\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "\n",
    "import sys\n",
    "\n",
    "# Print out system info\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e8c96740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UFC dataframe shape: (6528, 83)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/ufc-clean.csv')\n",
    "\n",
    "# Dataset shape and basic info\n",
    "print(\"UFC dataframe shape:\" , df.shape)  \n",
    "\n",
    "# TODO: encode this columns before exporting dataset in preprocess\n",
    "# Encode any categorical)\n",
    "categorical_cols = ['WeightClass', 'BlueStance', 'RedStance', 'Finish']\n",
    "le = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7fc71f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "to_drop = ['BlueAvgSigStrLanded', 'BlueAvgSubAtt', 'BlueAvgTDLanded', 'BlueTotalRoundsFought',\n",
    "           'BlueHeightCms', 'BlueReachCms', 'BlueWeightLbs', 'BlueAge', 'FinishRound', 'TotalFightTimeSecs', \n",
    "           'UFC_DebutDiff', 'CurrELODiff', 'ExpectedValueDiff']\n",
    "\n",
    "N = len(to_drop)\n",
    "for i in range(N):\n",
    "    if to_drop[i][:4] == \"Blue\":\n",
    "        to_drop.append(\"Red\" + to_drop[i][4:])\n",
    "\n",
    "numeric_df.drop(columns=to_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b8dae25",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "Despite our wide feature set to choose from, one pitfall from selecting too many can be overfitting. To prevent this, we can use methods like Recrusive Feature Elimination (RFE) provided by sklearn to help us select a set of features best for predicting UFC outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19494d64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['RedExpectedValue', 'BlueExpectedValue', 'BlueCurrentWinStreak',\n",
      "       'BlueAvgSigStrPct', 'BlueAvgTDPct', 'BlueWins', 'RedCurrentWinStreak',\n",
      "       'RedAvgSigStrPct', 'RedAvgTDPct', 'RedLosses', 'RedDaysSinceLastFight',\n",
      "       'BlueDaysSinceLastFight', 'RedCurrELO', 'BlueCurrELO',\n",
      "       'CurrentWinStreakDiff', 'AvgSigStrLandedDiff', 'AvgSubAttDiff',\n",
      "       'AvgTDLandedDiff', 'LossesDiff', 'TotalRoundsFoughtDiff', 'WinsDiff',\n",
      "       'ReachCmsDiff', 'AgeDiff', 'WinsByKOTKODiff', 'DaysSinceLastFightDiff'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "X = numeric_df.drop(columns=['Winner'], axis=1)\n",
    "y = numeric_df['Winner']\n",
    "\n",
    "estimator = RandomForestClassifier(\n",
    "    random_state=42, \n",
    "    n_estimators=10,  \n",
    "    max_depth=5       \n",
    ")\n",
    "\n",
    "rfe = RFE(estimator, n_features_to_select=25)\n",
    "rfe.fit(X, y)\n",
    "\n",
    "# Get the selected features\n",
    "selected_features = X.columns[rfe.support_]\n",
    "X_selected = X[selected_features]\n",
    "print(selected_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_selected,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262ab3e9",
   "metadata": {},
   "source": [
    "## Training a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "30db87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.6116\n",
      "Epoch 2, Loss: 0.7233\n",
      "Epoch 3, Loss: 0.6619\n",
      "Epoch 4, Loss: 0.6473\n",
      "Epoch 5, Loss: 0.6690\n",
      "Epoch 6, Loss: 0.5855\n",
      "Epoch 7, Loss: 0.6829\n",
      "Epoch 8, Loss: 0.6147\n",
      "Epoch 9, Loss: 0.5731\n",
      "Epoch 10, Loss: 0.8684\n",
      "Epoch 11, Loss: 1.0993\n",
      "Epoch 12, Loss: 0.6512\n",
      "Epoch 13, Loss: 0.6055\n",
      "Epoch 14, Loss: 0.8193\n",
      "Epoch 15, Loss: 0.4970\n",
      "Epoch 16, Loss: 0.8329\n",
      "Epoch 17, Loss: 0.4930\n",
      "Epoch 18, Loss: 0.6428\n",
      "Epoch 19, Loss: 0.8089\n",
      "Epoch 20, Loss: 0.7106\n",
      "Neural Network Accuracy: 0.600306\n"
     ]
    }
   ],
   "source": [
    "# First, let's normalize our data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Create PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)\n",
    "\n",
    "# Define our Neural Network\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_len):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.layer1 = nn.Linear(input_len, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.output_layer = nn.Linear(32, 2) # binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.layer1(x))\n",
    "        x = F.relu(self.layer2(x))\n",
    "        return self.output_layer(x)\n",
    "    \n",
    "\n",
    "# Init model\n",
    "nn_model = NN(X_train.shape[1])\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(nn_model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(20):\n",
    "    nn_model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = nn_model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# Evaluation\n",
    "nn_model.eval()\n",
    "correct, total = 0, 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_X, batch_y in test_loader:\n",
    "        outputs = nn_model(batch_X)\n",
    "\n",
    "        _, pred = torch.max(outputs.data, 1)\n",
    "        total += batch_y.size(0)\n",
    "        correct += (pred == batch_y).sum().item()\n",
    "\n",
    "nn_acc = correct / total\n",
    "print(f\"Neural Network Accuracy: {nn_acc:4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
